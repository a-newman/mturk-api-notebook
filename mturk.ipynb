{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the config file (see example). \n",
    "# will work with a config file for https://github.com/kimberli/mturk-template, \n",
    "# but a minimal example is included.\n",
    "# Also supports an additional feature, the \"variants\" key, which is a list of dictionaries. \n",
    "# If \"variants\" is specified, for each dictionary it contains, those keys will be meshed with the \"hitCreation\"\n",
    "# key and one task will be made per variant. Else, config[\"hitCreation\"][\"numTasks\"] versions of the same\n",
    "# task will be launched. \n",
    "CONFIG_PATH = \"./config.json\"\n",
    "\n",
    "# where to save downloaded results \n",
    "SAVE_PATH = \".\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3 import client\n",
    "import json\n",
    "import copy\n",
    "\n",
    "_USING_PROD = None\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "    hit_config = config['hitCreation']\n",
    "\n",
    "if hit_config['production']:\n",
    "    print(\"USING PROD\")\n",
    "    _USING_PROD = True\n",
    "    endpoint_url = 'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "else:\n",
    "    print(\"USING SANDBOX\")\n",
    "    _USING_PROD = False\n",
    "    endpoint_url = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "        \n",
    "cl = client('mturk', region_name='us-east-1', endpoint_url=endpoint_url)\n",
    "\n",
    "print(\"TASK URL: \" + hit_config['taskUrl'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make new HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety flags that prevent you from accidentally messing up your HITs. \n",
    "# Set to False except when you are performing these specific tasks. \n",
    "ALLOW_HIT_CREATION = False\n",
    "ALLOW_ASSIGNMENT_ADDITION = False\n",
    "ALLOW_CREATE_QUAL = False\n",
    "ALLOW_UPDATE_EXPIRATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of qualifications that you will use to filter potential workers. \n",
    "# These require that workers come from the US and have an approval rating >= 95%\n",
    "QUALS = [\n",
    "       {\n",
    "           'QualificationTypeId': '00000000000000000071',\n",
    "           'Comparator': 'EqualTo',\n",
    "           'LocaleValues': [{\n",
    "               'Country': 'US',\n",
    "           }],\n",
    "       },\n",
    "        \n",
    "       {\n",
    "           'QualificationTypeId': '000000000000000000L0',\n",
    "           'Comparator': 'GreaterThanOrEqualTo',\n",
    "           'IntegerValues': [\n",
    "               95\n",
    "           ],\n",
    "       },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a HIT in the form of an External Question inside an iFrame\n",
    "def create_hit(task):\n",
    "    questionText = \"<ExternalQuestion xmlns=\\\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/\"\n",
    "    questionText += \"2006-07-14/ExternalQuestion.xsd\\\">\\n<ExternalURL>\" + task['taskUrl']\n",
    "    questionText += \"</ExternalURL>\\n  <FrameHeight>700</FrameHeight>\\n</ExternalQuestion>\"\n",
    "\n",
    "    response = cl.create_hit(\n",
    "        MaxAssignments=task['numAssignments'],\n",
    "        AutoApprovalDelayInSeconds=604800,\n",
    "        LifetimeInSeconds=task['lifetime'],\n",
    "        AssignmentDurationInSeconds=task['duration'],\n",
    "        Reward=task['rewardAmount'],\n",
    "        Title=task['title'],\n",
    "        Keywords=task['keywords'],\n",
    "        Description=task['description'],\n",
    "        Question=questionText,\n",
    "        QualificationRequirements=QUALS,\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ALLOW_HIT_CREATION: \n",
    "    if config.get('variants', None): \n",
    "        print(\"creating \" + str(len(config['variants'])) + \" variants\")\n",
    "        for var in config['variants']: \n",
    "            task = copy.deepcopy(config)\n",
    "            task.update(var)\n",
    "            create_hit(task)\n",
    "    else: \n",
    "      print(\"creating \" + str(hit_config['numTasks']) + \" tasks\")\n",
    "      for i in range(hit_config['numTasks']):\n",
    "          create_hit(hit_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIT monitoring helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RESULTS = 1 # set equal to the number of outstanding hits you have \n",
    "\n",
    "hits = cl.list_hits(MaxResults=MAX_RESULTS)['HITs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all assignments created for a HIT\n",
    "def get_all_assignments(hitid): \n",
    "    assignments = []\n",
    "    should_continue = True\n",
    "    next_token = False\n",
    "    while (should_continue): \n",
    "        args = {\n",
    "            'HITId': hitid, \n",
    "            'MaxResults': 100\n",
    "        }\n",
    "        if (next_token): \n",
    "            args['NextToken'] = next_token\n",
    "        r = cl.list_assignments_for_hit(**args)\n",
    "        next_token = r.get('NextToken', False)\n",
    "        assignments.extend(r[\"Assignments\"])\n",
    "        should_continue = len(r[\"Assignments\"]) > 0\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Summarizes all hits in `hits` in a human-readable way \n",
    "def summarize_hits(hits): \n",
    "    print(len(hits))\n",
    "    ret = \"\"\n",
    "    for hit in hits: \n",
    "        expiration = hit['Expiration'].replace(tzinfo=None)\n",
    "        is_expired = expiration < datetime.datetime.now()\n",
    "        description = (\"Title: {title}\\n\" \n",
    "        \"ID: {hid}\\n\"\n",
    "        \"\\tAssignments left: {left}\\n\"\n",
    "        \"\\tAssignments completed: {complete}\\n\"\n",
    "        \"\\tAssignments pending: {pending}\\n\"\n",
    "        \"\\tExpired: {exp}\\n\\n\").format(\n",
    "            title=hit['Title'], \n",
    "            hid=hit['HITId'], \n",
    "            left=hit['NumberOfAssignmentsAvailable'], \n",
    "            complete=hit['NumberOfAssignmentsCompleted'], \n",
    "            pending=hit['NumberOfAssignmentsPending'],\n",
    "            exp=str(is_expired)\n",
    "        )\n",
    "        ret += description\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes all pending/submitted/approved assignments for all hits in `hits`\n",
    "def summarize_assignments(hits):\n",
    "    ret = \"\"\n",
    "    for hit in hits: \n",
    "        hid = hit['HITId']\n",
    "        title =  hit['Title']\n",
    "        name = \"HIT %s: %s\" % (hid, title)\n",
    "        ret += name + \"\\n\"\n",
    "        assignments = get_all_assignments(hid)\n",
    "        for a in assignments: \n",
    "            desc = \"\\tAssignment {aid}\\n\\t\\tStatus: {status}\\n\".format(aid=a['AssignmentId'], status=a['AssignmentStatus'])\n",
    "            ret += desc\n",
    "    print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_hits(): \n",
    "    global hits \n",
    "    global MAX_RESULTS\n",
    "    hits = cl.list_hits(MaxResults=MAX_RESULTS)['HITs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIT monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_hits()\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_hits()\n",
    "\n",
    "summarize_hits(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_hits()\n",
    "summarize_assignments(hits)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approve HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approves all outstanding hits created for the HITs in hits \n",
    "def approve_all(hits): \n",
    "    num_approved = 0\n",
    "    for hit in hits: \n",
    "        # make sure you keep getting assignments \n",
    "        assignments = get_all_assignments(hit[\"HITId\"])\n",
    "        #print(assignments)\n",
    "        for a in assignments: \n",
    "            if a['AssignmentStatus'] != 'Approved':\n",
    "                print(\"Approving assignment\")\n",
    "                num_approved += 1\n",
    "                cl.approve_assignment(AssignmentId=a['AssignmentId'])\n",
    "    print(\"Approved %d assignments\" % num_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refresh_hits()\n",
    "approve_all(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update expiration or num tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "\n",
    "# changes the expiration date on a HIT to days_from_now days in the future\n",
    "def update_expiration(hitid, days_from_now): \n",
    "    if ALLOW_UPDATE_EXPIRATION: \n",
    "        days = days_from_now*datetime.timedelta(days=1)\n",
    "        expire_time = datetime.datetime.now() + days\n",
    "\n",
    "        response = cl.update_expiration_for_hit(HITId=hitid, ExpireAt=expire_time)\n",
    "        print(response)\n",
    "        return response\n",
    "    else: \n",
    "        raise RuntimeException(\"This action is not currently enabled; set `ALLOW_UPDATE_EXPIRATION` to true to proceed with this action\")\n",
    "    \n",
    "def expire_hit(hit): \n",
    "    return update_expiration(hit, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_assignments(hitid, num_assignments): \n",
    "    if ALLOW_ASSIGNMENT_ADDITION: \n",
    "        response = cl.create_additional_assignments_for_hit(\n",
    "            HITId=hitid,\n",
    "            NumberOfAdditionalAssignments=num_assignments\n",
    "        )\n",
    "        print(response)\n",
    "        return response\n",
    "    else: \n",
    "        raise RuntimException(\"This action is not currently enabled; set `ALLOW_ASSIGNMENT_ADDITION` to true to proceed with this action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add custom qualifications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a qualification to disqualify workers who have done work before\n",
    "\n",
    "- uses \"negative qualification\" method from https://github.com/cloudyr/MturkR/wiki/qualifications-as-blocks\n",
    "\n",
    "### NOTE: quals are kept separate for the sandbox and prod. Make sure you are creating and assigning your quals in prod. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure of a new qualification \n",
    "NEW_QUAL = {\n",
    "    'Name': 'qualName',\n",
    "    'Keywords': 'Keywords for qual',\n",
    "    'Description': 'What is this qual, and why are you assigning it?',\n",
    "    'QualificationTypeStatus': 'Active',\n",
    "    'AutoGranted': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qual(new_qual):\n",
    "    if ALLOW_CREATE_QUAL: \n",
    "        response = cl.create_qualification_type(**new_qual)\n",
    "        print(response)\n",
    "        Id = response['QualificationTypeId']\n",
    "        print(\"id\", Id)\n",
    "        return Id\n",
    "    else: \n",
    "        raise RuntimException(\"This action is not currently enabled; set `ALLOW_CREATE_QUAL` to true to proceed with this action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all the custom quals you have created. \n",
    "def list_quals(): \n",
    "    response = cl.list_qualification_types(\n",
    "            Query='hasCompletedVisualGraphRecallTask',\n",
    "            MustBeRequestable=False\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "list_quals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_qual(qual_id, worker_ids): \n",
    "    for worker in worker_ids: \n",
    "        response = cl.associate_qualification_with_worker(\n",
    "                QualificationTypeId=qual_id, \n",
    "                WorkerId=worker,\n",
    "                IntegerValue=1,\n",
    "                SendNotification=False\n",
    "        )\n",
    "        print(response)\n",
    "        assert response\n",
    "        \n",
    "def get_workers_for_hit(hitid): \n",
    "    a = get_all_assignments(hitid)\n",
    "    workers = [a_['WorkerId'] for a_ in a]\n",
    "    return workers\n",
    "    \n",
    "def confirm_quals(qual_id, worker_ids): \n",
    "    for w in worker_ids: \n",
    "        response = cl.get_qualification_score(\n",
    "                QualificationTypeId=qual_id,\n",
    "                WorkerId=w\n",
    "        )\n",
    "        response = response['Qualification']\n",
    "        assert response['Status'] == 'Granted'\n",
    "        assert response['IntegerValue'] == 1\n",
    "        \n",
    "# Assigns qual with `qual_id` to every worker who has completed an assignment for the hit with `hitid`\n",
    "def assign_qual_for_hit(hitid, qual_id): \n",
    "    workers = get_workers_for_hit(hitid)\n",
    "    print(\"got workers\")\n",
    "    assign_qual(qual_id, workers)\n",
    "    print(\"assigned qual\")\n",
    "    confirm_quals(qual_id, workers)\n",
    "    print(\"confirmed qual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs \n",
    "import pprint\n",
    "\n",
    "def pretty_print(obj):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(obj)\n",
    "    pp = None\n",
    "\n",
    "# Downloads all the assignments completed for `hits` as a list of dictionaries. \n",
    "# If a download_path is given, also saves that data as json \n",
    "def get_assignment_content(hits, download_path=\"\", should_print=False): \n",
    "    all_responses = []\n",
    "    for hit in hits: \n",
    "        hitid = hit['HITId']\n",
    "        assignments = get_all_assignments(hitid)\n",
    "        for a in assignments:\n",
    "            a_xml = a['Answer']\n",
    "            #print(a_xml)\n",
    "            soup = bs(a_xml, \"lxml\")\n",
    "            answers = soup.find_all(\"answer\")\n",
    "            #print(answers)\n",
    "            results = {'HITId': hitid}\n",
    "            for ans in answers: \n",
    "                identifier = ans.find('questionidentifier').string\n",
    "                answer = ans.find('freetext').string\n",
    "                try: \n",
    "                    results[identifier] = json.loads(answer)\n",
    "                except:\n",
    "                    results[identifier] = answer\n",
    "            all_responses.append(results)\n",
    "    if should_print: \n",
    "        pretty_print(all_responses)\n",
    "    if download_path: \n",
    "        with open(download_path, 'w') as outfile: \n",
    "            json.dump(all_responses, outfile)\n",
    "    return all_responses\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = get_assignment_content(hits, download_path=SAVE_PATH, should_print=False)\n",
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
